---
---

@string{aps = {American Physical Society,}}

@inproceedings{kaur2021navigation,
  title={A Navigation System for Safe Routing},
  author={Kaur, Ramneek and Goyal, Vikram and Guntur, Venkata MV and Saini, Aakanksha and Sanadhya, Kaushal and Gupta, Ritvik and Ratra, Siftee},
  booktitle={2021 22nd IEEE International Conference on Mobile Data Management (MDM)},
  pages={240--243},
  year={2021},
  organization={IEEE}
}

@inproceedings{Kaur2018FindingTM,
  title={Finding the Most Navigable Path in Road Networks: A Summary of Results},
  author={Ramneek Kaur and Vikram Goyal and Venkata M. V. Gunturi},
  booktitle={DEXA},
  year={2018}
}

@InProceedings{10.1007/978-3-030-86517-7_24,
author="Venktesh, V *.
and Mohania, Mukesh
and Goyal, Vikram",
editor="Dong, Yuxiao
and Kourtellis, Nicolas
and Hammer, Barbara
and Lozano, Jose A.",
title="TagRec: Automated Tagging of Questions with Hierarchical Learning Taxonomy",
booktitle="ECML-PKDD",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="381--396",
abstract="Online educational platforms organize academic questions based on a hierarchical learning taxonomy (subject-chapter-topic). Automatically tagging new questions with existing taxonomy will help organize these questions into different classes of hierarchical taxonomy so that they can be searched based on the facets like chapter, topic. This task can be formulated as a flat multi-class classification problem. Usually, flat classification based methods ignore the semantic relatedness between the terms in the hierarchical taxonomy and the questions. Some traditional methods also suffer from the class imbalance issues as they consider only the leaf nodes ignoring the hierarchy. Hence, we formulate the problem as a similarity-based retrieval task where we optimize the semantic relatedness between the taxonomy and the questions. We demonstrate that our method helps to handle the unseen labels and hence can be used for taxonomy tagging in the wild, like the question-answer forums. In this method, we augment the question with its corresponding answer to capture more semantic information and then align the question-answer pair's contextualized embedding with the corresponding label (taxonomy) vector representations. The representations are aligned by fine-tuning a transformer based model with a loss function that is a combination of the cosine similarity and hinge rank loss. The loss function maximizes the similarity between the question-answer pair and the correct label representations and minimizes the similarity to unrelated labels. Finally, we perform extensive experiments on two real-world datasets. We empirically show that the proposed learning method outperforms representations learned using the multi-class classification method and other state of the art methods by 6{\%} as measured by Recall@k. We also demonstrate the performance of the proposed method on unseen but related learning content like the learning objectives without re-training the network.",
isbn="978-3-030-86517-7"
}

@article{DBLP:journals/corr/abs-2201-10982,
  author    = {Venktesh V and
               Mukesh K. Mohania and
               Vikram Goyal},
  title     = {Topic Aware Contextualized Embeddings for High Quality Phrase Extraction},
  journal   = {ECIR},
  volume    = {abs/2201.10982},
  year      = {2022},
  url       = {https://arxiv.org/abs/2201.10982},
  eprinttype = {arXiv},
  eprint    = {2201.10982},
  timestamp = {Tue, 01 Feb 2022 14:59:01 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2201-10982.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
